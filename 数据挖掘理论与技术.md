(数据挖掘 理论与技术)
## 贝叶斯分类
若设X是数据元组，在贝叶斯的术语中，X被看做“证据”。照例，X用n个属性集的测量描述。令H为某种假设，如数据元组X属于某特定类C。对于分类问题，希望确定P(H|X)，即给定“证据”或观测数据元组X，假设H成立的概率。换言之，给定X的属性描述，找出元组X属于类C的概率。
贝叶斯分类是基于贝叶斯定理的。贝叶斯定理如下：
$$
P(H|X)=\frac{(X|H)P(H)}{P(X)}
$$
以下是参数说明:
1. X: 样本数据
2. H: 某种假设
3. P(H): H的先验概率，即任意样本属于C的概率，此时样本X的属性完全未知
4. P(H|X): 在条件X下，H的后验概率，即已知某一样本的各个属性后，这一样本属于类C的概率。
5. P(X): X的先验概率，即此样本出现的概率。
6. P(X|H): 条件H下X的后验概率，即已知样本属于类C的情况下，该样本具有属性X的概率。
其中，P(X),P(H),P(X|H)可以由给定的数据估计，因此，完全可以利用贝叶斯定理计算出后验概率P(H|X). 也就是说，可以由样本的各个属性特征值估算出样本所属的类别。

### 朴素贝叶斯分类法

朴素贝叶斯分类法假定一个属性值对确定样本类别的影响独立于其他属性值。

朴素贝叶斯分类器的工作原理如下:
1. 假设数据集D，而A1,A2,...,A_n是数据集的n个属性，对于某一具体的样本，其属性值为(x1,x2,...,x_n)，其中x_i就是属性A_i的取值.
2. 假定有m个类，
$$
C={C_1,C_2,...,C_m}
$$
, 给定样本X，分类器将预测X的类别。对于朴素贝叶斯，当且仅当
$$
P(C_i|X)>P(C_j|X), 1\leq{j}\leq{m}, j\neq{1} (2)
$$
时，才可判定X属于类C.
3. 计算P(C_i)。若想得到最大的P(C_i|X)，根据式(2)，由于P(X)对于所有类均为常数，只需要P(X|C_i)P(C_i)最大即可。如果类的先验概率未知，则通常假定这些类是等概率的，即P(C_1)=P(C_2)=...=P(C_m)。类的先验概率可以用
$$
P(C_i)=\frac{C_{i,D}}{D} (3)
$$
进行估计，其中|C_{i,D}|是D中属于类C_i的样本数，|D|是数据集的总样本数。
4. 计算P(X|C_i}.朴素贝叶斯做了类条件独立的朴素假定，即在各属性间不存在依赖关系。这样，
$$
P(X|C_i)=\Pi^{n}_{k=1}P(x_k|C_i)=P(x_1|C_i)*P(x_2|C_i)*...*P(x_n|C_i) (4)
$$
可以容易地由训练样本估计概率P(x_1|C_i),P(x_2|C_i),...,P(x_k|C_i)。x_k是样本X属性A_k的值。
5. 为了预测X的类标签，对每个类C_i，计算P(X|C_i)P(C_i)，分类法预测元组X的类标签为C_i，当且仅当
$$
P(X|C_i)P(C_i)>P(X|C_j)P(C_j) 0\lt{j}\lt{m+1}, j\neq{i} (9)
$$

### 贝叶斯网络

### 贝叶斯网络

## 基于决策树的算法

### ID3算法

ID3算法的核心是：在决策树各级节点上选择属性时，以信息增益(Information Gain)作为属性的选择标准，以使在每一个非叶子节点进行测试时，能获取关于被测试记录最大的类别信息。

### C4.5算法

C4.5用信息增益率来选择属性，克服了用信息增益选择属性时偏向选择取值多的属性的不足。

### SLIQ算法

SLIQ算法对C4.5决策树分类算法的实现方法进行了改进，在决策树的构造过程中采用“预排序”和“广度优先策略”。

### SPRINT算法

SPRINT算法采用了Gini指数来判断分裂。

## 支持向量机

对于很多分类问题，例如最简单的，一个平面上的两类不同的点，如何将它用一条直线分开？在平面上无法实现，但是通过某种映射，将这些点映射到其他空间

（大数据分析：方法与应用）
# 贝叶斯分类与因果学习

## 贝叶斯分类

## 决策论与统计决策论

### 决策与风险

构成一个决策的三个基本元素是:
* 参数集
* 决策集
* 损失函数

定义5.1 (贝叶斯期望损失) 参数状态集$$$ \Theta=\{\theta_1,\theta_2,...\}, D=\{\delta\} $$$ 是决策集，损失函数是$$$ L(\theta,\delta) $$$, 那么贝叶斯期望损失
$$
R(\delta)E_{\Theta}[l(\theta,\delta)]=\int_{\Theta}{l(\theta,\delta)dP(\theta)}
$$

### 朴素贝叶斯分类






